{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCwe+GJmyD3sIlYktuA7pG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkumar84/sandbox/blob/master/Generative_AI_based_Proactive_Risk_Prevention_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4xn0fqgqYLuD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_data = pd.DataFrame({\n",
        "    'customer_id': [1, 2, 3],\n",
        "    'name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'location': ['Toronto', 'Vancouver', 'Calgary'],\n",
        "    'assets_insured': ['Car', 'Home', 'Car, Home']\n",
        "})\n"
      ],
      "metadata": {
        "id": "3rpyqBUHYT4-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_weather_data(location):\n",
        "    API_KEY = \"your_weather_api_key\"\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={API_KEY}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example weather data for each customer\n",
        "customer_data['weather_alert'] = customer_data['location'].apply(fetch_weather_data)\n"
      ],
      "metadata": {
        "id": "HN0kGZZoYUqw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_claims = pd.DataFrame({\n",
        "    'event': ['Hailstorm', 'Flood', 'Windstorm'],\n",
        "    'damage_cost': [5000, 10000, 2000],\n",
        "    'location': ['Toronto', 'Calgary', 'Vancouver'],\n",
        "    'alert': ['Move car to covered space', 'Secure basement', 'Trim tree branches']\n",
        "})\n"
      ],
      "metadata": {
        "id": "ycJ2j3OPYkET"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = [\n",
        "    \"Event: Hailstorm, Location: Toronto -> Move your car to a covered space.\",\n",
        "    \"Event: Flood, Location: Calgary -> Secure your basement to prevent water damage.\",\n",
        "    \"Event: Windstorm, Location: Vancouver -> Trim tree branches to reduce risk of falling debris.\"\n",
        "]\n",
        "\n",
        "with open(\"training_data.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(training_data))\n"
      ],
      "metadata": {
        "id": "uk_MT_ZVYqOk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"/content/training_data.txt\", tokenizer)\n"
      ],
      "metadata": {
        "id": "NVBKpuNQahiJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "import os\n",
        "import torch # Import torch\n",
        "\n",
        "# Load pretrained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Add the padding token to the tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Prepare the dataset\n",
        "def load_dataset(filepath, tokenizer):\n",
        "    # Ensure the file exists and is not empty\n",
        "    try:\n",
        "        with open(filepath, \"r\") as f:\n",
        "            content = f.read()\n",
        "            if not content:\n",
        "                raise ValueError(f\"The file at {filepath} is empty.\")\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"The file at {filepath} was not found.\")\n",
        "\n",
        "    # Tokenize the entire content of the file\n",
        "    encodings = tokenizer(content, return_encodings=True)\n",
        "\n",
        "    # Create a custom dataset class\n",
        "    class CustomDataset(object):\n",
        "        def __init__(self, encodings):\n",
        "            self.encodings = encodings\n",
        "        def __getitem__(self, idx):\n",
        "            return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # Now torch is defined\n",
        "        def __len__(self):\n",
        "            return len(self.encodings.input_ids)\n",
        "\n",
        "    # Return an instance of the custom dataset\n",
        "    return CustomDataset(encodings)\n",
        "\n",
        "\n",
        "# Correct file path (add a './' before to specify current dir)\n",
        "dataset = load_dataset(\"./training_data.txt\", tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-risk-alerts\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "trainer.train()\n",
        "model.save_pretrained(\"./gpt2-risk-alerts\")\n",
        "tokenizer.save_pretrained(\"./gpt2-risk-alerts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "4iTUITI1alUW",
        "outputId": "3218afbd-621a-4b8b-f5b7-88a28ccd9151"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keyword arguments {'return_encodings': True} not recognized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [42/42 01:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./gpt2-risk-alerts/tokenizer_config.json',\n",
              " './gpt2-risk-alerts/special_tokens_map.json',\n",
              " './gpt2-risk-alerts/vocab.json',\n",
              " './gpt2-risk-alerts/merges.txt',\n",
              " './gpt2-risk-alerts/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load fine-tuned model\n",
        "risk_alert_model = pipeline(\"text-generation\", model=\"./gpt2-risk-alerts\")\n",
        "\n",
        "# Generate alerts for customers\n",
        "def generate_alert(event, location):\n",
        "   input_text = f\"Event: {event}, Location: {location} ->\"\n",
        "   alert = risk_alert_model(input_text, max_length=50, num_return_sequences=1)\n",
        "   return alert[0]['generated_text'].split(\"->\")[1]\n",
        "\n",
        "# Example: Generating alerts\n",
        "customer_data['proactive_alert'] = customer_data.apply(\n",
        "   lambda row: generate_alert('Hailstorm', row['location']), axis=1\n",
        ")\n",
        "print(customer_data[['name', 'location', 'proactive_alert']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o8BnVn4a2SH",
        "outputId": "19c32b9b-3ac1-4a0a-ff90-c2fd366ec1df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      name   location                                    proactive_alert\n",
            "0    Alice    Toronto   Hailstorm, Damage Duration: 5 and above, dama...\n",
            "1      Bob  Vancouver                            Rainstorm, Location (1 \n",
            "2  Charlie    Calgary  , Location in a rainstorm. Hailstorm:\\n\\nDamag...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "def send_email(to_email, subject, message):\n",
        "    # Replace with your actual SMTP server and credentials\n",
        "    smtp_server = \"smtp.mail.com\"  # For example, Gmail's SMTP server\n",
        "    from_email = \"maheshkumar@techie.com\"  # Replace with your email address\n",
        "    password = \"\"  # Replace with your email password\n",
        "\n",
        "    msg = MIMEText(message)\n",
        "    msg['Subject'] = subject\n",
        "    msg['From'] = from_email\n",
        "    msg['To'] = to_email\n",
        "\n",
        "    with smtplib.SMTP(smtp_server, 587) as server:\n",
        "        server.starttls()\n",
        "        server.login(from_email, password)\n",
        "        server.sendmail(from_email, to_email, msg.as_string())\n",
        "\n",
        "# Example: Notify a customer\n",
        "send_email(\"mahitherealtor@gmail.com\", \"Proactive Risk Alert\", \"A hailstorm is expected in your area. Move your car to a covered space.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "pmJ_ysMHdcNz",
        "outputId": "88c23f4c-a671-4a4a-bc74-d01f5c38131e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SMTPAuthenticationError",
          "evalue": "(535, b'Authentication credentials invalid')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSMTPAuthenticationError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f1f8f039e3f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Example: Notify a customer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msend_email\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mahitherealtor@gmail.com\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Proactive Risk Alert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"A hailstorm is expected in your area. Move your car to a covered space.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-f1f8f039e3f6>\u001b[0m in \u001b[0;36msend_email\u001b[0;34m(to_email, subject, message)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmtplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSMTP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmtp_server\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m587\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarttls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_email\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendmail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_email\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_email\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/smtplib.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self, user, password, initial_response_ok)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# We could not login successfully.  Return result of last attempt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mlast_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarttls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcertfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/smtplib.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self, user, password, initial_response_ok)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auth_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mauthmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 (code, resp) = self.auth(\n\u001b[0m\u001b[1;32m    740\u001b[0m                     \u001b[0mauthmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     initial_response_ok=initial_response_ok)\n",
            "\u001b[0;32m/usr/lib/python3.11/smtplib.py\u001b[0m in \u001b[0;36mauth\u001b[0;34m(self, mechanism, authobject, initial_response_ok)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m235\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m503\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mSMTPAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauth_cram_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchallenge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSMTPAuthenticationError\u001b[0m: (535, b'Authentication credentials invalid')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQqdiGH5dodR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}